# Transfer-Learning Project

**Abstract**  
In this research we look at how the transfer learning methodology can be applied to text classification, particularly to classify non-functional requirement datasets with models previously trained on a big data corpus like hundreds of Wikipedia articles.  

The purpose of this research is to establish a concrete benchmark of how successful an open-source data can be applied for training deep neural network when there is a lack of desirable training data. It is really hard to find a sufficient number of non-functional requirements for training deep neural network, so we substitute those with human-written sentences from Wikipedia articles.  

Trained binary and multiclass models are tested on a corpus of non-functional requirements, results are recorded and analyzed to draw a conclusion. Wikipedia data corpus is found to be a good training substitute for broadly scoped class like security, but less so for narrow-scoped classes like operability and usability. This conclusion comes with a lot of caveats, as well as opportunities for future work and model improvements.
